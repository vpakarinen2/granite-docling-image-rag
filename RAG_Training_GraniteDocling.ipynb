{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2b7f8",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install transformers docling_core pillow faiss-gpu-cu12 sentence-transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601c4f8-b4f6-44d8-8be5-cc2fdc15dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"<HF_token>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867e877",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from docling_core.types.doc.document import DocTagsDocument\n",
    "from docling_core.types.doc import DoclingDocument\n",
    "from transformers.image_utils import load_image\n",
    "from pathlib import Path\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_ID = \"ibm-granite/granite-docling-258M\"\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "vlm = AutoModelForVision2Seq.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16 if DEVICE == \"cuda\" else torch.float32,\n",
    "    _attn_implementation=\"sdpa\"\n",
    ").to(DEVICE)\n",
    "vlm.eval()\n",
    "\n",
    "print(\"Graniteâ€‘Docling loaded on\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae83aa6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_markdown(image_path, prompt_text=None):\n",
    "    if prompt_text is None:\n",
    "        prompt_text = (\n",
    "            \"Extract all readable text, numeric, and labeled content from this image, \"\n",
    "            \"including headlines, paragraphs, numbers, labels, and convert to markdown.\"\n",
    "        )\n",
    "        \n",
    "    image = load_image(image_path)\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": prompt_text}]}]\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    \n",
    "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output_ids = vlm.generate(**inputs, max_new_tokens=8192)\n",
    "        \n",
    "    offset = inputs.input_ids.shape[1]\n",
    "    generated = output_ids[:, offset:]\n",
    "    doctags = processor.batch_decode(generated, skip_special_tokens=False)[0].lstrip()\n",
    "    doc_obj = DocTagsDocument.from_doctags_and_image_pairs([doctags], [image])\n",
    "    doc = DoclingDocument.load_from_doctags(doc_obj, document_name=\"Document\")\n",
    "    \n",
    "    return doc.export_to_markdown()\n",
    "\n",
    "img_dir = Path(\"/workspace/images\")\n",
    "out_dir = Path(\"/workspace/corpus\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for image_file in img_dir.glob(\"*.[pj][np]g\"):\n",
    "    print(f\"Converting {image_file.name}...\")\n",
    "    md_text = convert_to_markdown(str(image_file))\n",
    "    md_path = out_dir / f\"{image_file.stem}.md\"\n",
    "    md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "    \n",
    "    print(f\"Preview of {md_path.name}:\\n{md_text[:500]}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e38f01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, faiss\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import Iterator, Dict, Sequence\n",
    "from pathlib import Path\n",
    "\n",
    "def read_text(path: Path): return path.read_text(errors=\"ignore\")\n",
    "\n",
    "def iter_chunks(text: str, size=1000, overlap=200):\n",
    "    step = max(1, size - overlap)\n",
    "    for i in range(0, len(text), step):\n",
    "        yield text[i:i+size]\n",
    "\n",
    "records = []\n",
    "for md_file in out_dir.glob(\"*.md\"):\n",
    "    txt = read_text(md_file)\n",
    "    for idx, ch in enumerate(iter_chunks(txt)):\n",
    "        records.append({\"source\": str(md_file), \"chunk\": ch, \"chunk_index\": idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270375e2",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "texts = [r[\"chunk\"] for r in records]\n",
    "emb = embedder.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "emb = emb / (np.linalg.norm(emb, axis=1, keepdims=True)+1e-12)\n",
    "index = faiss.IndexFlatIP(emb.shape[1])\n",
    "index.add(emb)\n",
    "\n",
    "print(\"Index ready:\", index.ntotal, \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b302e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve(query, k=3):\n",
    "    qv = embedder.encode([query], convert_to_numpy=True)\n",
    "    qv = qv / (np.linalg.norm(qv, axis=1, keepdims=True)+1e-12)\n",
    "    D, I = index.search(qv, k)\n",
    "    return [(int(i), float(D[0, n])) for n, i in enumerate(I[0])]\n",
    "\n",
    "query = \"Type your query here\"\n",
    "hits = retrieve(query, k=3)\n",
    "\n",
    "for i, score in hits:\n",
    "    print(round(score, 3), records[i][\"source\"])\n",
    "    print(records[i][\"chunk\"][:200], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d65131",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "gen_model_id = \"google/gemma-2-2b-it\"\n",
    "tok = AutoTokenizer.from_pretrained(gen_model_id)\n",
    "gen = AutoModelForCausalLM.from_pretrained(\n",
    "    gen_model_id,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b557c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(question, context_chunks):\n",
    "    context = \"\\n\\n\".join(context_chunks)\n",
    "    return f\"Use the context to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "top_k_chunks = [records[i][\"chunk\"] for i, _ in hits]\n",
    "prompt = build_prompt(query, top_k_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf8172",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tok(prompt, return_tensors=\"pt\", truncation=True).to(gen.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = gen.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "generated_tokens = out[0, inputs.input_ids.shape[1]:]\n",
    "answer = tok.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
